# data_eng_instructions
Test task for J&amp;J


java -version - be sure spark is working above jvm (scala native)
pip install pyspark


python main.py

For testing:
pip install nose
pip install pytest
-> restart ide -> invalidate caches

Run pytest in bash

For pyspark: - install java 17
sdk install java 17.0.11.fx-zulu -> for example
pip install "pyarrow>=15.0.0"
pip install "grpcio>=1.48.1"
pip install "grpcio-status >= 1.48.1"
pip install "zstandard >= 0.25.0"